{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa1d9d0",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Diplomatura en Ciencias de Datos, Aprendizaje Automático y sus Aplicaciones\n",
    "\n",
    "Autores: Matías Oria, Antonela Sambuceti, Pamela Pairo, Benjamín Ocampo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31a365",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Definición de funciones *helper*\n",
    "Inicialmente se definen funciones que se utilizaron durante la selección e\n",
    "imputación de columnas del conjunto de datos obtenido en\n",
    "`melbourne_exploration.py` y almacenados en un servidor para su acceso remoto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d93259",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import (base, decomposition, feature_extraction, impute,\n",
    "                     neighbors, preprocessing)\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "\n",
    "def plot_imputation_graph(imputations: List[Tuple[str, pd.DataFrame]],\n",
    "                          missing_cols: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Makes a group of density plots according to the number of columns on the\n",
    "    dataframes inside @imputations. @imputations must be a list of pairs\n",
    "    (@method_name, @value_df) where each @value_df has the same @missing_cols\n",
    "    obtained by its corresponding imputer @method_name.\n",
    "    \"\"\"\n",
    "    _, axs = plt.subplots(len(missing_cols), figsize=(10, 10))\n",
    "    for ax, col_name in zip(axs, missing_cols):\n",
    "        data = pd.concat([\n",
    "            imputation_df[[col_name]].assign(method=method)\n",
    "            for method, imputation_df in imputations\n",
    "        ])\n",
    "        seaborn.kdeplot(data=data, x=col_name, hue=\"method\", ax=ax)\n",
    "\n",
    "\n",
    "def impute_by(values: Union[np.array, pd.DataFrame],\n",
    "              missing_col_names: List[str],\n",
    "              estimator: base.BaseEstimator) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a dataframe that fills null entries of @values according to\n",
    "    @estimator. @missing_col_names are labels that will be assigned when\n",
    "    created. @values might have columns that doesn't have null values, such that\n",
    "    the IterativeImputer class takes advantage of it in order to estimate\n",
    "    missing values.\n",
    "    \"\"\"\n",
    "    indicator = impute.MissingIndicator()\n",
    "    indicator.fit_transform(values)\n",
    "\n",
    "    imputer = impute.IterativeImputer(\n",
    "        random_state=0, estimator=estimator)\n",
    "    imputed_values = imputer.fit_transform(values)\n",
    "    imputed_df = pd.DataFrame(imputed_values[:, indicator.features_],\n",
    "                              columns=missing_col_names)\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac79e189",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "URL_MELB_HOUSING_FILTERED = \"https://www.famaf.unc.edu.ar/~nocampo043/melb_housing_filtered_df.csv\"\n",
    "URL_MELB_SUBURB_FILTERED = \"https://www.famaf.unc.edu.ar/~nocampo043/melb_suburb_filtered_df.csv\"\n",
    "\n",
    "melb_housing_df = pd.read_csv(URL_MELB_HOUSING_FILTERED)\n",
    "melb_suburb_df = pd.read_csv(URL_MELB_SUBURB_FILTERED)\n",
    "melb_combined_df = melb_housing_df.join(melb_suburb_df, on=\"suburb_id\")\n",
    "melb_combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8386ae7",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Encoding\n",
    "Con el fin de poder entrenar un modelo bajo las variables en `melb_combined_df`,\n",
    "se deben codificar aquellas que sean categóricas. Para ello, se utiliza *One-Hot\n",
    "Encoding* donde se muestran dos posibles métodos distintos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b83e7",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Dict Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94268f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    \"housing_room_segment\", \"housing_bathroom_segment\", \"housing_type\",\n",
    "    \"suburb_region_segment\"\n",
    "]\n",
    "numerical_cols = [\n",
    "    \"housing_price\", \"housing_land_size\", \"suburb_rental_dailyprice\"\n",
    "]\n",
    "feature_cols = categorical_cols + numerical_cols\n",
    "features = list(melb_combined_df[feature_cols].T.to_dict().values())\n",
    "\n",
    "vectorizer = feature_extraction.DictVectorizer()\n",
    "feature_matrix = vectorizer.fit_transform(features)\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28cbcb5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b9a27d",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Se obtiene una matriz de $13206 \\times 20$ cuyas columnas son las que se\n",
    "muestran por `get_feature_names()`.\n",
    "\n",
    "Del total de variables de `melb_combined_df`, se excluyen `suburb_name` y\n",
    "`suburb_council_area` con el fin de obtener una matriz cuyo espacio en memoria\n",
    "no imposibilite la imputación de las variables numéricas `housing_year_built` y\n",
    "`housing_building_area` en una sección posterior. A su vez, se presentó otra\n",
    "forma de realizar una codificación *one-hot* con fin complementario. No\n",
    "obstante, se trabajó sobre la matriz dada por el método `Dict Vectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd23caf",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "### One-Hot Encoding\n",
    "Otro forma posible de obtener la matriz de *features* es por medio de la clase\n",
    "`OneHotEncoder` realizando la codificación sobre `categorical_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b02038",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "feature_matrix_ohe = np.hstack([\n",
    "    ohe.fit_transform(melb_combined_df[categorical_cols]),\n",
    "    melb_combined_df[numerical_cols]\n",
    "])\n",
    "feature_matrix_ohe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5f71d8",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "De manera similar, se obtiene la matriz codificada donde las primeras 17\n",
    "columnas corresponden a la codificación de las variables categóricas, y las 3\n",
    "restantes a las numéricas que no requerían este paso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c418b8",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Imputación por KNN\n",
    "En esta sección se procedió a imputar las variables `housin_year_built` y\n",
    "`housing_building_area` con el fin de incluirlas en la matriz de *features*.\n",
    "Para ello, se realizaron imputaciones univariadas y multivariadas, es decir,\n",
    "utilizando solamente valores no nulos de dichas variables para realizar la\n",
    "imputación, en comparación a, aprovechar todos los *features* disponibles en la\n",
    "matriz obtenida en la sección anterior. A su vez, esta comparación también se\n",
    "realizó estandarizando las variables con el fin de verificar si influía en la\n",
    "imputación resultante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafd33a",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Sin estandarizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69688f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "missing_cols = [\"housing_year_built\", \"housing_building_area\"]\n",
    "estimator = neighbors.KNeighborsRegressor(n_neighbors=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ece04a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "missing_df = melb_combined_df[missing_cols]\n",
    "original_df = missing_df.dropna()\n",
    "all_df = np.hstack([missing_df, feature_matrix.todense()])\n",
    "\n",
    "knn_missing_cols = impute_by(missing_df, missing_cols, estimator)\n",
    "knn_all_cols = impute_by(all_df, missing_cols, estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0edf2e3",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Para la comparación se crean 3 *dataframes*:\n",
    "  - `original_df`: Contiene las columnas de `housing_year_built` y\n",
    "    `housing_building_area` eliminando aquellos valores faltantes.\n",
    "  - `missing_df`: Similar a `original_df` pero sin eliminar las entradas nulas.\n",
    "  - `all_df`: Contiene todas las *features* obtenidas en la sección de\n",
    "    codificación junto a las de `missing_df`.\n",
    "\n",
    "Posteriormente, se procedió a imputar los valores faltantes que ocurren en las\n",
    "entradas de `missing_df` y `all_df` por medio de `impute_by`, una de las\n",
    "funciones *helper* definidas en la primera sección, generando un nuevo\n",
    "*dataframe* con aquellos datos completados por el estimador `KNeighbors`.\n",
    "\n",
    "Por último, las distribuciones de las observaciones de los *dataframes*\n",
    "resultantes se comparan por medio de un gráfico de densidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407af1a3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "imputations = [\n",
    "    (\"original\", original_df),\n",
    "    (\"knn - missing cols\", knn_missing_cols),\n",
    "    (\"knn - all cols\", knn_all_cols)\n",
    "]\n",
    "plot_imputation_graph(imputations, missing_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c342790",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Se puede observar que la distribución de `housing_year_built` luego de imputar\n",
    "por medio de todas las columnas captura en mejor medida la tendencia\n",
    "correspondiente a su original. Especialmente para aquellas viviendas con poca\n",
    "antigüedad al momento de la venta. Similarmente, puede darse la misma\n",
    "aseveración para la variable `housing_bulding_area`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83da8c",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Con estandarizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5507d7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "original_scaled_df = pd.DataFrame(scaler.fit_transform(original_df),\n",
    "                                  columns=missing_cols)\n",
    "knn_scaled_missing_cols = impute_by(scaler.fit_transform(missing_df),\n",
    "                                    missing_cols, estimator)\n",
    "knn_scaled_all_cols = impute_by(scaler.fit_transform(all_df), missing_cols,\n",
    "                                estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561dc3ba",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "imputations = [\n",
    "    (\"scaled original\", original_scaled_df),\n",
    "    (\"knn - scaled missing cols\", knn_scaled_missing_cols),\n",
    "    (\"knn - scaled all cols\", knn_scaled_all_cols)\n",
    "]\n",
    "plot_imputation_graph(imputations, missing_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0b5c7a",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Escalando los datos de manera previa a la imputación no pareció afectar la\n",
    "elección de un método por sobre otro. Se puede observar que la manera en que se\n",
    "distribuyen ambas variables es similar al caso anterior salvo por el cambio de\n",
    "escala en los ejes x e y. Por lo tanto, se optó por incluir la imputación con\n",
    "todas las *features* sin estandarizado previo a la matriz resultante de la\n",
    "sección anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9dfb0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "feature_matrix = np.hstack([feature_matrix.todense(), knn_all_cols])\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad036f5",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fbf9f2",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Análisis de Componentes Principales (`PCA`)\n",
    "Antes de realizar el `PCA` se realiza la estandarización de los datos, es decir\n",
    "a cada dato se le resta su media y se lo divide por el desvío estándar. La\n",
    "estandarización permite trabajar con variables medidas en distintas unidades y\n",
    "así dar el mismo peso a todas las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b2b55",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "feature_matrix_standarized = preprocessing.StandardScaler().fit_transform(\n",
    "    feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050d3d7",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "A continuación se muestra a modo de ejemplo el cambio de los valores antes y\n",
    "después de la estandarización para la fila 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4704dc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "print('\\nAntes de estandarizar \\n%s' %feature_matrix[5])\n",
    "print('\\nDespués de estandarizar \\n%s' %feature_matrix_standarized[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d308a3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "_, nof_components = feature_matrix_standarized.shape\n",
    "pca = decomposition.PCA(n_components=nof_components)\n",
    "principal_components = pca.fit_transform(feature_matrix_standarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7571e451",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Se muestra la varianza explicada por cada componente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796d5d8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07796c46",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Para una mejor comprensión se calcula el porcentaje acumulado explicado por cada\n",
    "componente. El primer componente explica el 17,09% de la variación. Luego, el\n",
    "primer y segundo componente explican el 27.32% de la variación y así\n",
    "sucesivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15759f3f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "acc_variance_percent = np.cumsum(np.round(explained_variance, decimals=4) * 100)\n",
    "acc_variance_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487cb87",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Se eligen las primeras 17 componentes que explican el 98,71% de la variación y\n",
    "también a partir de ese valor se llega al *plateau* (meseta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e774b22",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel('% de varianza explicada')\n",
    "plt.xlabel('Componentes Principales')\n",
    "plt.title('PCA')\n",
    "plt.ylim(20, 110)\n",
    "plt.xticks(range(nof_components))\n",
    "plt.plot(acc_variance_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68e9111",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "El siguiente gráfico muestra en conjunto la varianza explicada por cada\n",
    "componente (barra) y la varianza acumulada (línea escalonada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef344496",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "acc_variance = np.cumsum(explained_variance)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(explained_variance)),\n",
    "        explained_variance,\n",
    "        alpha=0.5,\n",
    "        align='center',\n",
    "        label='Varianza explicada individual')\n",
    "plt.step(range(len(acc_variance)),\n",
    "         acc_variance,\n",
    "         where='mid',\n",
    "         label='Varianza explicada acumulada')\n",
    "plt.ylabel('Radio de varianza explicada')\n",
    "plt.xlabel('Componentes principales')\n",
    "plt.legend(loc='best')\n",
    "plt.xticks(range(nof_components))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0430c70",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Composición del resultado\n",
    "Para finalizar, se crea un nuevo *dataframe* que contenga las codificaciones de\n",
    "las variables categóricas y numéricas, las imputaciones de columnas que\n",
    "presentaban valores faltantes, y las primeras 17 componentes principales\n",
    "observadas en la sección anterior. El conjunto resultante es puesto a\n",
    "disposición para su acceso remoto a través de la siguiente URL:\n",
    "- [Codificación del conjunto de\n",
    "  datos](https://www.famaf.unc.edu.ar/~nocampo043/encoded_melb_df.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63753de",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "nof_selected_components = 17\n",
    "new_columns = vectorizer.get_feature_names()\n",
    "\n",
    "new_columns = (\n",
    "    vectorizer.get_feature_names() + missing_cols +\n",
    "    [f\"pca_{component_id}\" for component_id in range(nof_selected_components)])\n",
    "\n",
    "encoded_melb_df = pd.DataFrame(\n",
    "    data=np.hstack([\n",
    "        feature_matrix,\n",
    "        principal_components[:, :nof_selected_components]]),\n",
    "    columns=new_columns)\n",
    "encoded_melb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_melb_df.to_csv(\"encoded_melb_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\"",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('usr')",
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
